<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>bpl_notes</title>
<!-- 2018-02-13 Tue 00:55 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Vihari Piratla" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">bpl_notes</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. Paper</a></li>
<li><a href="#sec-2">2. Motivation</a></li>
<li><a href="#sec-3">3. What?</a></li>
<li><a href="#sec-4">4. Bayesian Program Learning (at a glance)</a></li>
<li><a href="#sec-5">5. Modeling Strokes</a></li>
<li><a href="#sec-6">6. Composing strokes (relations)</a></li>
<li><a href="#sec-7">7. Generative Model</a>
<ul>
<li><a href="#sec-7-1">7.1. Type Level variables</a></li>
<li><a href="#sec-7-2">7.2. Token Level variables</a></li>
</ul>
</li>
<li><a href="#sec-8">8. Learning&#x2026;</a>
<ul>
<li><a href="#sec-8-1">8.1. Learning Primitives</a></li>
<li><a href="#sec-8-2">8.2. Learning start positions</a></li>
<li><a href="#sec-8-3">8.3. Learning relations and token variability</a></li>
<li><a href="#sec-8-4">8.4. Global transformation</a></li>
</ul>
</li>
<li><a href="#sec-9">9. Inference</a>
<ul>
<li><a href="#sec-9-1">9.1. Character skeletons and random parses</a></li>
</ul>
</li>
<li><a href="#sec-10">10. Approximate inference for one shot classification</a></li>
<li><a href="#sec-11">11. Results</a>
<ul>
<li><a href="#sec-11-1">11.1. Visual Turing test</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Paper</h2>
<div class="outline-text-2" id="text-1">
<p>
<a href="http://web.mit.edu/cocosci/Papers/Science-2015-Lake-1332-8.pdf">Human-level concept learning through probabilistic program induction</a>
</p>

<p>
<a href="https://cims.nyu.edu/~brenden/LakeEtAl2015Science_supp.pdf">Supplementary</a>
</p>

<p>
<i>published in Science Magazine, 2015</i>
</p>

<p>
Highly related publication by Hinton in NIPS 2006: <a href="http://www.cs.toronto.edu/~hinton/absps/vnips.pdf">Inferring Motor Programs from Images of Handwritten Digits</a>
</p>

<p>
Notes: This paper stems out of the intersection of psychology, cognitive and computer science
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Motivation</h2>
<div class="outline-text-2" id="text-2">
<ol class="org-ol">
<li>People can generalize easily from just a few examples while machines need to see (on the order) millions of labeled examples.
</li>
<li>Humans have a much richer representation of the learned concepts which enable explanation and imagination.
</li>
</ol>

<blockquote>
<p>
The center problem of AI is the question: What is the letter 'a'?
</p>

<p>
For any program to handle letterforms with the flexibility that human beings do, it would have to possess full-scale artificial intelligence‚Äù
&#x2014; Douglas Hofstadter, "Metamagical Themas: Questing For The Essence Of Mind And Pattern"
</p>
</blockquote>
</div>
</div>


<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> What?</h2>
<div class="outline-text-2" id="text-3">
<p>
Bayesian Program Learning (BPL) for modelling and generating new examples on the Omniglot dataset.
Concepts represented as probabilistic programs.
</p>
<ul class="org-ul">
<li>Beats other models and human on one-shot classification
</li>
<li>Proposed a visual turing test to qualitatively measure the generalisation capabilities of a model.
</li>
</ul>

<p>
Omniglot is a dataset containing 1,623 characters from 50 writing systems.
The dataset is collected from Amazon Mechanical Turk (AMT), several hand-drawn versions of the images are collected from human subjects who draw a depicted symbol.
Resulting in a list of &lt;x, y, time&gt; tuples.
</p>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> Bayesian Program Learning (at a glance)</h2>
<div class="outline-text-2" id="text-4">

<div class="figure">
<p><img src="./md_slides/_images/bpl_omniglot.png" alt="bpl_omniglot.png" />
</p>
<p><span class="figure-number">Figure 1:</span> Program learning and classification on Omniglot</p>
</div>

<p>
The images in the top row are the best five parses for the instance, different colors correspond to different strokes.
New instance is classified based on how well the program for a type explains the new instance. 
</p>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> Modeling Strokes</h2>
<div class="outline-text-2" id="text-5">
<p>
Every stroke is composed of sub-parts called primitives. 
Primitives are drawn from a library of cubic splines such as in the figure below. 
</p>

<div class="figure">
<p><img src="./md_slides/_images/bpl_plib.png" alt="bpl_plib.png" />
</p>
<p><span class="figure-number">Figure 2:</span> Library of primitives</p>
</div>

<p>
Every stroke is a list of triplets: &lt; <b>z</b>, <b>x</b>, y &gt;.
<i>z</i> selects one of the primitives from the library, <i>x</i> \(\in \mathbb{R}^10\) gives the position of each of the five control points of the spline and y denotes the scale of the shape. 
One sub-part starts where the sub-part before ends.
</p>
</div>
</div>

<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> Composing strokes (relations)</h2>
<div class="outline-text-2" id="text-6">
<p>
Strokes are composed and their spatial relations modeled as one of 
</p>
<ul class="org-ul">
<li>Independent &#x2013; does not depend on the position of the previous stroke
</li>
<li>Start, end &#x2013; if it starts at beginning or at the end of the previous stroke.
</li>
<li>Along &#x2013; connects somewhere along the previous stroke. 
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7"><span class="section-number-2">7</span> Generative Model</h2>
<div class="outline-text-2" id="text-7">
<p>
\(P(\psi, \theta^{(1)}, \cdots, \theta^{(m)}, I^{(1)}\cdots I^{(m)}) = P(\psi)\prod_{i=1}^{m}P(I^{(m)}|\theta^{(m)})P(\theta^{(m)}|\psi)\)
</p>

<p>
\(\psi\) is type level model parameter
\(\theta\) is the token level model parameter that capture the motor level variance in generation.
</p>
</div>

<div id="outline-container-sec-7-1" class="outline-3">
<h3 id="sec-7-1"><span class="section-number-3">7.1</span> Type Level variables</h3>
<div class="outline-text-3" id="text-7-1">
<p>
\(\psi=\{\kappa, R, S\}\)
</p>

<div class="figure">
<p><img src="./md_slides/_images/bpl_typevars.png" alt="bpl_typevars.png" />
</p>
<p><span class="figure-number">Figure 3:</span> Type level variables</p>
</div>
</div>
</div>

<div id="outline-container-sec-7-2" class="outline-3">
<h3 id="sec-7-2"><span class="section-number-3">7.2</span> Token Level variables</h3>
<div class="outline-text-3" id="text-7-2">
<p>
\(\theta^{(m)} = \{L^{(m)}, x^{(m)}, y^{(m)}, R^{(m)}, A^{(m)}, {\sigma_b}^{(m)}, \epsilon^{(m)}\}\)
</p>

<div class="figure">
<p><img src="./md_slides/_images/bpl_tokenvars.png" alt="bpl_tokenvars.png" />
</p>
<p><span class="figure-number">Figure 4:</span> Token Variables</p>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-8" class="outline-2">
<h2 id="sec-8"><span class="section-number-2">8</span> Learning&#x2026;</h2>
<div class="outline-text-2" id="text-8">
</div><div id="outline-container-sec-8-1" class="outline-3">
<h3 id="sec-8-1"><span class="section-number-3">8.1</span> Learning Primitives</h3>
<div class="outline-text-3" id="text-8-1">
<ul class="org-ul">
<li>After spatially and temporally standardizing the data, 55,000 sub-parts<sup><a id="fnr.1" name="fnr.1" class="footref" href="#fn.1">1</a></sup> trajectories are collected.
</li>
<li>GMM with 1250 mixtures (over 30 alphabets) is used to partition the trajectories and learn primitives.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-8-2" class="outline-3">
<h3 id="sec-8-2"><span class="section-number-3">8.2</span> Learning start positions</h3>
<div class="outline-text-3" id="text-8-2">
<p>
The position of the first and the second stokes is learned by fitting a multinomial grid over the images.
An aggregated model for the rest of the strokes. 
</p>
</div>
</div>
<div id="outline-container-sec-8-3" class="outline-3">
<h3 id="sec-8-3"><span class="section-number-3">8.3</span> Learning relations and token variability</h3>
<div class="outline-text-3" id="text-8-3">
<p>
A more complicated model is fit over the 800 background images and statics are collected over these fits to compute the relational params, positional noise. 
\(\sigma_x, \sigma_y, \sigma_\tau\) are estimated from how much the shape and scale change from program that is fit on one example when used on another example.
</p>
</div>
</div>
<div id="outline-container-sec-8-4" class="outline-3">
<h3 id="sec-8-4"><span class="section-number-3">8.4</span> Global transformation</h3>
<div class="outline-text-3" id="text-8-4">
<ul class="org-ul">
<li>The glabal transformation (translation and rotation) is estimated simply by computing the variance of transformations over the background images.
</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-sec-9" class="outline-2">
<h2 id="sec-9"><span class="section-number-2">9</span> Inference</h2>
<div class="outline-text-2" id="text-9">
<p>
Inference is tricky since it requires exploration of combinatorial space over number of (sub-)parts, types, relations etc. 
MCMC is found to be slow and gets stuck in local minima.
</p>
</div>

<div id="outline-container-sec-9-1" class="outline-3">
<h3 id="sec-9-1"><span class="section-number-3">9.1</span> Character skeletons and random parses</h3>
<div class="outline-text-3" id="text-9-1">

<div class="figure">
<p><img src="./md_slides/_images/bpl_skeleton.png" alt="bpl_skeleton.png" />
</p>
<p><span class="figure-number">Figure 5:</span> Character skeleton from an image</p>
</div>


<div class="figure">
<p><img src="./md_slides/_images/bpl_parses.png" alt="bpl_parses.png" />
</p>
<p><span class="figure-number">Figure 6:</span> Generating Random Parses</p>
</div>

<p>
The points in red are the junction points.
For random parses, an action needs to be taken at each of these red points.
\(P(A) = exp(-\lambda\theta_A)\)
</p>

<ul class="org-ul">
<li>Sub-strokes are identified by greedily adding, removing or replacing the pauses in order to maximize the observed trajectory.
Once the strokes and their sub-parts are identified, K (=5) best candidate programs: \(\psi\) and \(\theta^{(m)}\) are identified.
</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-sec-10" class="outline-2">
<h2 id="sec-10"><span class="section-number-2">10</span> Approximate inference for one shot classification</h2>
<div class="outline-text-2" id="text-10">

<div class="figure">
<p><img src="./md_slides/_images/bpl_approx_infer.png" alt="bpl_approx_infer.png" />
</p>
<p><span class="figure-number">Figure 7:</span> One shot classification</p>
</div>

<p>
Better results are found when considering conditional from both the sides i.e. \(P(I^{(c)}|I^{(t)})\) and \(P(I^{(t)}|I^{(c)})\)
\(I^{(c)}\) is the seen examples and \(I^{(t)}\) is the new test image.
</p>
</div>
</div>

<div id="outline-container-sec-11" class="outline-2">
<h2 id="sec-11"><span class="section-number-2">11</span> Results</h2>
<div class="outline-text-2" id="text-11">
<p>
Beats human (and other deepnets) on one-shot classification task.
</p>

<div class="figure">
<p><img src="./md_slides/_images/bpl_results.png" alt="bpl_results.png" />
</p>
<p><span class="figure-number">Figure 8:</span> Results</p>
</div>

<p>
Compared with lesion models that give up on either learning to learn an aspect of the model such as sub-stroke shape/scale, stroke relations or position.
The model is also compared with the case when an image is modeled with just one cubic b-spline. 
</p>
</div>
<div id="outline-container-sec-11-1" class="outline-3">
<h3 id="sec-11-1"><span class="section-number-3">11.1</span> Visual Turing test</h3>
<div class="outline-text-3" id="text-11-1">
<p>
I could only score 55% on this test.
</p>

<div class="figure">
<p><img src="./md_slides/_images/vturing.png" alt="vturing.png" />
</p>
<p><span class="figure-number">Figure 9:</span> Visual Turing Test</p>
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" name="fn.1" class="footnum" href="#fnr.1">1</a></sup> <p class="footpara">
sub-parts are defined to be the trajectories between two pauses. 
</p></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="date">Date: 11-02-1993</p>
<p class="author">Author: Vihari Piratla</p>
<p class="date">Created: 2018-02-13 Tue 00:55</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 25.3.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
